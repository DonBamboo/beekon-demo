# Beekon.ai Database Migration Guide

This directory contains complete migration files to perfectly replicate the Supabase database from project `apzyfnqlajvbgaejfzfm`.

## üìä Migration Contents

### Generated Migration Files

1. **`001_recreate_complete_schema.sql`** - Complete database schema
   - All 13 core tables with exact column definitions
   - All foreign key relationships and constraints  
   - All indexes for optimal performance
   - All triggers for automation
   - Row Level Security setup
   - Proper permissions and grants

2. **`002_recreate_all_data.sql`** - Complete data export (FIXED - no auth trigger issues)
   - Workspaces (14 rows) ‚úÖ Complete
   - Profiles (16 rows) ‚úÖ Complete
   - Instructions for exporting remaining ~19K rows

3. **`003_recreate_views_and_security.sql`** - Views and security
   - 4 materialized views with exact definitions
   - Complete RLS policies for all tables
   - Security functions and utilities

## üóÇÔ∏è Database Structure

### Core Tables (Updated Counts)
- **`workspaces`** - Multi-tenant organization structure (14 rows)
- **`profiles`** - User profiles with workspace associations (16 rows)
- **`websites`** - Monitored websites (28 rows)
- **`topics`** - Analysis topics per website (280 rows)
- **`prompts`** - LLM prompts per topic (2,916 rows)
- **`analysis_sessions`** - Analysis batch tracking (24 rows)
- **`llm_analysis_results`** - Brand mention results (8,317 rows)
- **`competitors`** - Competitor tracking (25 rows)
- **`competitor_analysis_results`** - Competitor mention results (7,311 rows)
- **`website_settings`** - Website-specific configurations (11 rows)
- **`export_history`** - Export audit trail (101 rows)
- **`api_keys`** - API access management (0 rows)
- **`competitor_status_log`** - Status change audit (0 rows)

### Materialized Views
- **`mv_competitor_daily_metrics`** - Daily competitor performance
- **`mv_competitive_gap_analysis`** - Brand vs competitor comparison
- **`mv_competitor_share_of_voice`** - Voice share analysis
- **`mv_competitor_performance`** - Performance tracking with trends

## üöÄ Migration Instructions

### Option 1: Local Supabase Development

1. **Setup local Supabase**:
   ```bash
   # Initialize Supabase project
   supabase init
   supabase start
   ```

2. **Apply migrations in order**:
   ```bash
   # Apply schema
   supabase db reset
   psql postgresql://postgres:postgres@localhost:54322/postgres -f supabase/migrations/001_recreate_complete_schema.sql
   
   # Apply core data
   psql postgresql://postgres:postgres@localhost:54322/postgres -f supabase/migrations/002_recreate_all_data.sql
   
   # Apply views and security
   psql postgresql://postgres:postgres@localhost:54322/postgres -f supabase/migrations/003_recreate_views_and_security.sql
   ```

### Option 2: New Supabase Project

1. **Create new Supabase project** at https://supabase.com
2. **Get connection details** from project settings
3. **Apply migrations**:
   ```bash
   # Replace with your actual connection details
   psql "postgresql://postgres:[password]@db.[ref].supabase.co:5432/postgres" -f 001_recreate_complete_schema.sql
   psql "postgresql://postgres:[password]@db.[ref].supabase.co:5432/postgres" -f 002_recreate_all_data.sql  
   psql "postgresql://postgres:[password]@db.[ref].supabase.co:5432/postgres" -f 003_recreate_views_and_security.sql
   ```

## üìã Bulk Data Export Instructions

The `002_recreate_all_data.sql` file contains the foundational data (workspaces and profiles) but due to the large volume (~19K rows), you need to export the remaining data from the source database.

### Step 1: Connect to Source Database
```bash
# Replace with actual connection details for apzyfnqlajvbgaejfzfm
psql "postgresql://postgres:[password]@db.apzyfnqlajvbgaejfzfm.supabase.co:5432/postgres"
```

### Step 2: Export All Table Data
Run these commands in the source database to generate INSERT statements:

```sql
-- Export websites data (28 rows)
\copy (SELECT format('INSERT INTO beekon_data.websites VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L);', id, domain, display_name, crawl_status, is_active, last_crawled_at, workspace_id, created_at, updated_at) FROM beekon_data.websites ORDER BY created_at) TO 'websites_data.sql';

-- Export topics data (280 rows)  
\copy (SELECT format('INSERT INTO beekon_data.topics VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, topic_name, topic_keywords, website_id, is_active, recommendation_text, reporting_text, priority, created_at, updated_at) FROM beekon_data.topics ORDER BY created_at) TO 'topics_data.sql';

-- Export prompts data (2,916 rows)
\copy (SELECT format('INSERT INTO beekon_data.prompts VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, prompt_text, prompt_type, priority, topic_id, is_active, strengths, opportunities, recommendation_text, reporting_text, expected_llms, created_at, updated_at) FROM beekon_data.prompts ORDER BY created_at) TO 'prompts_data.sql';

-- Export analysis sessions (24 rows)
\copy (SELECT format('INSERT INTO beekon_data.analysis_sessions VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, analysis_name, website_id, user_id, workspace_id, status, configuration, progress_data, error_message, started_at, completed_at, created_at, updated_at) FROM beekon_data.analysis_sessions ORDER BY created_at) TO 'sessions_data.sql';

-- Export LLM analysis results (8,317 rows)
\copy (SELECT format('INSERT INTO beekon_data.llm_analysis_results VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, prompt_id, llm_provider, website_id, is_mentioned, rank_position, sentiment_score, confidence_score, response_text, summary_text, analyzed_at, created_at, analysis_session_id) FROM beekon_data.llm_analysis_results ORDER BY created_at) TO 'llm_results_data.sql';

-- Export competitors (25 rows)
\copy (SELECT format('INSERT INTO beekon_data.competitors VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, website_id, competitor_domain, competitor_name, is_active, analysis_frequency, last_analyzed_at, created_at, updated_at, analysis_status, analysis_started_at, analysis_completed_at, analysis_progress, last_error_message) FROM beekon_data.competitors ORDER BY created_at) TO 'competitors_data.sql';

-- Export competitor analysis results (7,311 rows)
\copy (SELECT format('INSERT INTO beekon_data.competitor_analysis_results VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, competitor_id, llm_analysis_id, llm_provider, is_mentioned, rank_position, sentiment_score, confidence_score, response_text, summary_text, analyzed_at, created_at, prompt_id, analysis_session_id) FROM beekon_data.competitor_analysis_results ORDER BY created_at) TO 'competitor_results_data.sql';

-- Export website settings (11 rows)
\copy (SELECT format('INSERT INTO beekon_data.website_settings VALUES(%L, %L, %L, %L, %L);', id, website_id, settings, created_at, updated_at) FROM beekon_data.website_settings ORDER BY created_at) TO 'website_settings_data.sql';

-- Export export history (101 rows)
\copy (SELECT format('INSERT INTO beekon_data.export_history VALUES(%L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L, %L);', id, user_id, export_type, format, filename, file_size, status, filters, date_range, metadata, error_message, created_at, started_at, completed_at, updated_at) FROM beekon_data.export_history ORDER BY created_at) TO 'export_history_data.sql';
```

### Step 3: Combine and Apply Data
```bash
# Combine all data files into complete migration
cat 002_recreate_all_data.sql websites_data.sql topics_data.sql prompts_data.sql sessions_data.sql llm_results_data.sql competitors_data.sql competitor_results_data.sql website_settings_data.sql export_history_data.sql > complete_data_migration.sql

# Apply to target database
psql "postgresql://..." -f complete_data_migration.sql
```

## ‚úÖ Verification Steps

After migration, verify the recreation was successful:

```sql
-- Check table row counts match source
SELECT 
    schemaname,
    tablename,
    n_tup_ins as row_count
FROM pg_stat_user_tables 
WHERE schemaname = 'beekon_data' 
ORDER BY n_tup_ins DESC;

-- Expected results:
-- llm_analysis_results: 8,317 rows
-- competitor_analysis_results: 7,311 rows  
-- prompts: 2,916 rows
-- topics: 280 rows
-- websites: 28 rows
-- export_history: 101 rows
-- competitors: 25 rows
-- analysis_sessions: 24 rows
-- website_settings: 11 rows
-- workspaces: 14 rows
-- profiles: 16 rows

-- Check materialized views are populated
SELECT COUNT(*) FROM beekon_data.mv_competitor_daily_metrics; -- Expected: 383
SELECT COUNT(*) FROM beekon_data.mv_competitive_gap_analysis; -- Expected: 1,618  
SELECT COUNT(*) FROM beekon_data.mv_competitor_share_of_voice; -- Expected: 248
SELECT COUNT(*) FROM beekon_data.mv_competitor_performance; -- Expected: 355

-- Refresh views to ensure they work
SELECT beekon_data.refresh_competitor_views();

-- Test RLS policies (should return data only for authenticated user)
SELECT COUNT(*) FROM beekon_data.websites; -- Should respect RLS
```

## üîê Security Features

The migration includes comprehensive security:

- **Row Level Security (RLS)** enabled on all tables
- **Workspace isolation** - users only see data from their workspaces
- **API key management** with rate limiting and scopes
- **Audit logging** for status changes and exports
- **Secure functions** for data access and view refreshing

## üìù Key Architectural Features

1. **Multi-tenant architecture** with workspaces
2. **Proper foreign key relationships** (competitor_analysis_results uses competitor_id, not website_id)
3. **Performance optimized** with comprehensive indexing
4. **Full-text search** capabilities on analysis results
5. **Materialized views** for fast dashboard queries
6. **Trigger-based** updated_at timestamp management

## üîß Post-Migration Tasks

1. **Update application configuration** to point to new database
2. **Refresh materialized views** regularly (recommended: every hour)
3. **Set up backup schedules** for the new database
4. **Update any hardcoded project references** in the application
5. **Test all application features** to ensure compatibility

## üö® Important Notes

- **Foreign key dependencies**: Data must be loaded in the correct order (workspaces ‚Üí profiles ‚Üí websites ‚Üí topics ‚Üí prompts ‚Üí analysis results)
- **Large dataset**: The complete dataset is 47K+ rows, so plan for appropriate timeouts and connection limits
- **Materialized views**: These need to be refreshed periodically to stay current with data changes
- **RLS testing**: Test thoroughly with different user accounts to ensure proper data isolation

## üìû Support

If you encounter issues during migration:
1. Check the PostgreSQL logs for specific error messages
2. Verify foreign key relationships are maintained in data order
3. Ensure all required extensions are installed
4. Confirm proper connection permissions for the target database

---

**Generated**: 2025-01-12  
**Source Project**: `apzyfnqlajvbgaejfzfm`  
**Total Rows**: ~47,000 records across 13 tables  
**Migration Files**: 3 files + bulk data exports